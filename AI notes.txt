FRÅGA A-B PÅ BÅDA MODELLERNA

Convolutional Model:

Run #1:
	Settings:
	Epochs = 50
	Learning Rate = 0.01
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (8, 8)

	accuracy = 0,9736 & 0,9736 (train först validation sen) 
	loss = 0,0969 & 0,09685 (train först validation sen)
	moved data = 18,06
	rotated data = 85,99
	
	1m 55s
	
Run #2:
	Settings:
	Epochs = 50
	Learning Rate = 1
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (8, 8)

	accuracy = 0,1127 & 0,106 (train först validation sen) 
	loss = 2,302 & 2,302 (train först validation sen)
	moved data = 11,35
	rotated data = 7,32

	At 1.00 Learning Rate, accuracy and loss does not change and is at a stable 0.1 and 2.4 in value.
	försökte hitta gränsen där det  blir sämre.

	1m 50s

Run #3:
	Settings:
	Epochs = 50
	Learning Rate = 0.5
	Validation Split = 0.5
	Batch Size = 256
	Kernel Size = (8, 8)
	
	accuracy = 0,9873 & 0,9731 (train först validation sen) 
	loss = 0,03895 & 0,1066 (train först validation sen)
	moved data = 21,51
	rotated data = 85,01
	
	At 0.5 Learning Rate, the validation model is very uneven and differs in accuracy & loss value a lot. The training model is more stable but still worse than 0.01 LR.
	försökte hitta en gräns emellan 0.01 och 1 då 1 var för stort

	1m 48s

Run #4:
	Settings:
	Epochs = 50
	Learning Rate = 0.4
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (8, 8)

	accuracy = 0,9954 & 0,9826 (train först validation sen) 
	loss = 0,01648 & 0,07377 (train först validation sen)
	moved data = 19,32
	rotated data = 86,84

	At 0.2 Learning Rate, the validation and training model is much more even than at the previous 0.5 LR. The accuracy stops at around 0.985 and the loss rate stops at around 0.02.
	
	1m 49s
	
Run #5:
	Settings:
	Epochs = 50
	Learning Rate = 0.45
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (8, 8)

	accuracy = 0,9993 & 0,9869 (train först validation sen) 
	loss = 3,9969 * 10^-3 & 0,05882 (train först validation sen)
	moved data = 21,2
	rotated data = 91,1

	At 0.11 LR, the training accuracy is even and stops at around 0.9946 and it's loss value at 0.02. The validation model has 		more uneven values in both accuracy and loss. It stops at around 0.985 accuracy and 0.055 loss.
	
	1m 50s










BATCH SIZE


Run #6:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 128
	Kernel Size = (8, 8)


	accuracy = 0,9974 & 0,9852 (train först validation sen) 
	loss = 0,01113 & 0,05159 (train först validation sen)
	moved data = 22,04
	rotated data = 90,16
	
	cut the step speed in half but did not change the total time, more steps!

	1m 58s

Run #7:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 64
	Kernel Size = (8, 8)

	accuracy = 0,9993 & 0,9862 (train först validation sen) 
	loss = 4,2165 *10^-3 & 0,05742 (train först validation sen)
	moved data = 22,01
	rotated data = 89,24
	
	cuts the step speed down to 4ms/step
	
	2m 24s


	accuracy går upp och loss ned men på förlust av både moved data och rotated data ifall vi går ner mera

			NEURONER

Run #8:
	Settings:
	Epochs = 50
	Learning Rate = 0.01
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (8, 8)
	Neuroner =  64

	accuracy = 0,9952 & 0,9868 (train först validation sen) 
	loss = 0,0177 & 0,04404 (train först validation sen)
	moved data = 22,11
	rotated data = 89,21

	With four times more neurons (64) than before the model achieved 0.9911/0.9854 (train/valid) accuracy and 0.03172/0.04813 		loss. It took way longer to run through all the epochs. 
	
	step speed 27m/s	

	4m 13s
	
Run #9:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (8, 8)
	Neuroner = 128

	accuracy = 0,9958 & 0,9877 (train först validation sen) 
	loss = 0,01724 & 0,04193 (train först validation sen)
	moved data = 22,21
	rotated data = 89,22

	With 128 neurons the model achieved 0.09916/0.9857 (train/valid) accuracy and 0.03089/0.04789 loss. It took almost 8 minutes 
	
	step speed 52 m/s

	8m 4s

			KERNEL SIZE OCH STRIDE

Run #10:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (10, 10)
	Strides = (2, 2)

	accuracy = 0,9904 & 0,983 (train först validation sen) 
	loss = 0,03371 & 0,0539 (train först validation sen)
	moved data = 22,17
	rotated data = 90,51
	
	41s	
Run #11:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (10, 10)
	Strides = (1, 1)

	accuracy = 0,9938 & 0,9853 (train först validation sen) 
	loss = 0,02231 & 0,04759 (train först validation sen)
	moved data = 21,07
	rotated data = 90,85
	
	1m 58s
Run #12:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (8, 8)
	Strides = (2, 2)

	accuracy = 0,9892 & 0,9827 (train först validation sen) 
	loss = 0,03571 & 0,0574 (train först validation sen)
	moved data = 23,3
	rotated data = 87,76
	
	37s	
	
			LAYERS
Run #12:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 256
	layers = 2

	accuracy = 0,9989 & 0,9872 (train först validation sen) 
	loss = 5,7956*10^-3 & 0,05679 (train först validation sen)
	moved data = 22,64
	rotated data = 91,66
	
	8min 43s

 
Non-Convolutional Model:

Run #1:
	Settings:
	Epochs = 50
	Learning Rate = 0.01
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (8, 8)

	accuracy = 0,9301 & 0,9309 (train först validation sen) 
	loss = 0,2475 & 0,2423 (train först validation sen)
	moved data = 11,98
	rotated data = 75,77
	
	7s
	
Run #2:
	Settings:
	Epochs = 50
	Learning Rate = 1
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (8, 8)

	accuracy = 0,9773 & 0,9478 (train först validation sen) 
	loss = 0,07375 & 0,2152 (train först validation sen)
	moved data = 15,66
	rotated data = 75,02

	försökte hitta gränsen där det  blir sämre.

	7s

Run #3:
	Settings:
	Epochs = 50
	Learning Rate = 0.5
	Validation Split = 0.5
	Batch Size = 256
	Kernel Size = (8, 8)
	
	accuracy = 0,996 & 0,9662 (train först validation sen) 
	loss = 0,01788 & 0,1424 (train först validation sen)
	moved data = 16,22
	rotated data = 81,52
	
	At 0.5 Learning Rate, the validation model is very uneven and differs in accuracy & loss value a lot. The training model is more stable but still worse than 0.01 LR.
	försökte hitta en gräns emellan 0.01 och 1 då 1 var för stort

	7s

Run #4:
	Settings:
	Epochs = 50
	Learning Rate = 0.4
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (8, 8)

	accuracy = 0,9937 & 0,966 (train först validation sen) 
	loss = 0,02512 & 0,1394 (train först validation sen)
	moved data = 15,8
	rotated data = 81,69

	At 0.2 Learning Rate, the validation and training model is much more even than at the previous 0.5 LR. The accuracy stops at around 0.985 and the loss rate stops at around 0.02.
	
	7s
	
Run #5:
	Settings:
	Epochs = 50
	Learning Rate = 0.45
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (8, 8)

	accuracy = 0,9955 & 0,9647 (train först validation sen) 
	loss = 0,02002 & 0,1433 (train först validation sen)
	moved data = 16,3
	rotated data = 81,71

	At 0.11 LR, the training accuracy is even and stops at around 0.9946 and it's loss value at 0.02. The validation model has 		more uneven values in both accuracy and loss. It stops at around 0.985 accuracy and 0.055 loss.
	
	7s




				BATCH SIZE


Run #6:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 128
	Kernel Size = (8, 8)


	accuracy = 0,9866 & 0,9681 (train först validation sen) 
	loss = 0,04838 & 0,116 (train först validation sen)
	moved data = 15,36
	rotated data = 82,68
	
	cut the step speed in half but did not change the total time, more steps!

	12s

Run #7:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 64
	Kernel Size = (8, 8)

	accuracy = 0,9935 & 0,9633 (train först validation sen) 
	loss = 0,02563 & 0,1467 (train först validation sen)
	moved data = 16,79
	rotated data = 81,38
	
	cuts the step speed down to 4ms/step
	
	23s


	accuracy går upp och loss ned men på förlust av både moved data och rotated data ifall vi går ner mera

				NEURONER

Run #8:
	Settings:
	Epochs = 50
	Learning Rate = 0.01
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (8, 8)
	Neuroner =  64

	accuracy = 0,9855 & 0,9724 (train först validation sen) 
	loss = 0,05508 & 0,1008 (train först validation sen)
	moved data = 16,18
	rotated data = 83,17

	With four times more neurons (64) than before the model achieved 0.9911/0.9854 (train/valid) accuracy and 0.03172/0.04813 		loss. It took way longer to run through all the epochs. 
	
	step speed 800u/s	

	8s
	
Run #9:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (8, 8)
	Neuroner = 128

	accuracy = 0,9903 & 0,9732 (train först validation sen) 
	loss = 0,0412 & 0,08945 (train först validation sen)
	moved data = 15,62
	rotated data = 85,43

	With 128 neurons the model achieved 0.09916/0.9857 (train/valid) accuracy and 0.03089/0.04789 loss. It took almost 8 minutes 
	
	step speed 1 m/s

	9s











c. Det vanliga neuronnätet (non-convolutional) gick igenom varje epok mycket snabbare än CNN. 
Ett Non-convolutional neural network går igenom en bild varje pixel för sig, medan ett convolutional NN går igenom en bild med större block som innehåller sub-NNs.

d. Under första körningen vinner CNN i jämförelse med ANN då efter 50 epoker hade den en bättre accuracy med mycket mindre loss. Dock tar CNN mycket längre tid att köra igenom alla 50 epoker i jämförelse med ANN.

e. Lär sig lite mer, men tar väldigt mycket mer tid. Inte värt att använda då modeller med mindre neuroner kan lära sig ungefär lika mycket på mycket kortare tid.

f. Att öka Kernel Size över (10, 10) försämrar modellen. Att öka Strides försämrar också modellen. 

g. Precisionen blir mycket bättre men detta i kostnad mot träningstid, som även ökar väldigt mycket.





8. Egna experiment:

Conv:
Test #1:
	Settings:
	Epochs = 50
	Learning Rate = 0.3
	Batch Size = 64
	Kernel Size = (8, 8)
	Strides = (1, 1)
	Layers = 2
	Neurons = 32


	1/0.9897 Accuracy (train/validation). 2.1445*10^-5/0.007792 (train/validation) Loss. Moved: 23.74 avg. Rotated: 89.92 avg.
	21 minutes 17 seconds elapsed.


Test #2:
	Settings:
	Epochs = 50
	Learning Rate = 0.35
	Batch Size = 64
	Kernel Size = (8, 8)
	Strides = (1, 1)
	Layers = 1
	Neurons = 16


	0.9963/0.9794 Accuracy (train/validation). 0.01093/0.1201 Loss (train/validation). Moved: 21.01 avg. Rotated: 86.47 avg.
	2 minutes 15 seconds elapsed.


Test #3:
	Settings:
	Epochs = 50
	Learning Rate = 0.4
	Batch Size = 64
	Kernel Size = (8, 8)
	Strides = (1, 1)
	Layers = 1
	Neurons = 32


	1/0.9875 Accuracy. 2.9956*10^-4/0.06705 Loss. Moved: 21.65 avg. Rotated: 90.17 avg.
	2 minutes 57 seconds elapsed.


Test #4:
	Settings:
	Epochs = 50
	Learning Rate = 0.4
	Batch Size = 32
	Kernel Size = (8, 8)
	Strides = (1, 1)
	Layers = 1
	Neurons = 64

	1/0.9866 Accuracy. 8.0342*10^-5/0.0895 Loss. Moved: 21.27 avg. Rotated: 89.29 avg.
	5m 22s elapsed.


Test #5:
	Settings:
	Epochs = 50
	Learning Rate = 0.35
	Batch Size = 128
	Kernel Size = (8, 8)
	Strides = (1, 1)
	Layers = 1
	Neurons = 32


	1/0.9877 Accuracy. 8.7093*10^-4/0.05637 Loss. Moved: 21.86 avg. Rotated: 89.97 avg.
	2m 59s elapsed.


Answer: Test #3 was the best!! around!!! nothing's gonna ever keep me down!!!



non-conv:
Test #1:
	Settings:
	Epochs = 50
	Learning Rate = 0.3
	Batch Size = 64´
	Neurons = 32


	0.994/0.9651 Accuracy. 0.01946/0.2458 Loss. Moved: 15.54 avg. Rotated: 82.28 avg.
	23s elapsed.


Test #2:
	Settings:
	Epochs = 50
	Learning Rate = 0.4
	Batch Size = 64
	Neurons = 64


	1/0.9769 Accuracy. 6.8722*10^-4/0.1196 Loss. Moved: 16.73 avg. Rotated: 85.98 avg.
	24s elapsed.


Test #3:
	Settings:
	Epochs = 50
	Learning Rate = 0.4
	Batch Size = 64
	Neurons = 128


	1/0.9789 Accuracy. 5.4733*10^-4/0.09306 Loss. Moved: 17.39 avg. Rotated: 87.68 avg.
	25s elapsed.


Test #4:
	Settings:
	Epochs = 50
	Learning Rate = 0.4
	Batch Size = 64
	Neurons = 1024


	1/0.9827 Accuracy. 4.2237*10^-4/0.07589 Loss. Moved: 17.51 avg. Rotated: 88.36 avg.
	1m 19s elapsed.

Test #5:
	Settings:
	Epochs = 50
	Learning Rate = 0.4
	Batch Size = 64
	Neurons = 16384


	1/0.9842 Accuracy. 4.05*10^-4/0.07187 Loss. Moved: 17.39 avg. Rotated: 88.42 avg.
	13m 47s elapsed.


Test #6:
	Settings:
	Epochs = 50
	Learning Rate = 0.4
	Batch Size = 32
	Neurons = 1024


	1/0.9836 Accuracy. 1.5577*10^-4/0.08045 Loss. Moved: 17.69 avg. Rotated: 89.04 avg.
	2m 36s elapsed.


Answer: Test #6 was best!! around!!! nothing's gonna ever keep me down!!

