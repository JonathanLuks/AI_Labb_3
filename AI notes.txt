Non-Convolutional-Model:

Run #1:
	Settings:
	Epochs = 50
	Learning Rate = 0.01
	Validation Split = 0.2
	Batch Size = 256

	Notes:
	The First epoch is the slowest, 2ms/step whilst the rest are 1ms/step.
	Loss decreases pretty rapidly in the beginning. From 1.8717 to 1.1499 to 0.7855 within only three (3) epochs.
	Accuracy also increases pretty rapidly. 0.4001 to 0.7349 to 0.8248 within three epochs.
	Val_loss: 1.4338 -> 0.8800 -> 0.6505
	Val_accuracy: 0.6294 -> 0.8172 -> 0.8547

	In 50 epochs the non-conv AI manages to reach 0.2396 loss and 0.9314 accuracy.

Run #2:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 256

	Each step took about 800us (microseconds). The training model stopped at around 0.98 accuracy and 0.05 loss, while the 		validation model stopped around 0.965 accuracy and 0.125 loss.

Run #3:
	Settings:
	Epochs = 50
	Learning Rate = 1
	Validation Split = 0.2
	Batch Size = 256

	Each step took about 800us. The validation model gets really uneven in both accuracy and loss values.


Run #4:
	Settings:
	Epochs = 50
	Learning Rate = 0.05
	Validation Split = 0.2
	Batch Size = 256

	The training and validation model is really even but instead the accuracy and loss value is much worse. They stop at 		0.9669/0.9611 (train/validation) accuracy & 0.1171/0.1394 loss.

Run #5:
	Settings:
	Epochs = 50
	Learning Rate = 0.05
	Validation Split = 0.2
	Batch Size = 256

	At two times the amount of neurons (64) the model achieved 0.9729/0.9658 (train/valid) accuracy and 0.09774/0.1221 loss.
	The times between each epoch was around 900us/step, so a bit slower than with less neurons.


Run #6:
	Settings:
	Epochs = 50
	Learning Rate = 0.05
	Validation Split = 0.2
	Batch Size = 256

	At two times the amount of neurons (128) the model achieved 0.9769/0.9685 (train/valid) accuracy and 0.08346/0.1103 loss.
	The times between each epoch was around 960us/step, so a bit slower than with less neurons.



FRÅGA A-B PÅ BÅDA MODELLERNA

Convolutional Model:

Run #1:
	Settings:
	Epochs = 50
	Learning Rate = 0.01
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (8, 8)

	accuracy = 0,9736 & 0,9736 (train först validation sen) 
	loss = 0,0969 & 0,09685 (train först validation sen)
	moved data = 18,06
	rotated data = 85,99
	
	1m 55s
	
Run #2:
	Settings:
	Epochs = 50
	Learning Rate = 1
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (8, 8)

	accuracy = 0,1127 & 0,106 (train först validation sen) 
	loss = 2,302 & 2,302 (train först validation sen)
	moved data = 11,35
	rotated data = 7,32

	At 1.00 Learning Rate, accuracy and loss does not change and is at a stable 0.1 and 2.4 in value.
	försökte hitta gränsen där det  blir sämre.

	1m 50s

Run #3:
	Settings:
	Epochs = 50
	Learning Rate = 0.5
	Validation Split = 0.5
	Batch Size = 256
	Kernel Size = (8, 8)
	
	accuracy = 0,9873 & 0,9731 (train först validation sen) 
	loss = 0,03895 & 0,1066 (train först validation sen)
	moved data = 21,51
	rotated data = 85,01
	
	At 0.5 Learning Rate, the validation model is very uneven and differs in accuracy & loss value a lot. The training model is more stable but still worse than 0.01 LR.
	försökte hitta en gräns emellan 0.01 och 1 då 1 var för stort

	1m 48s

Run #4:
	Settings:
	Epochs = 50
	Learning Rate = 0.4
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (8, 8)

	accuracy = 0,9954 & 0,9826 (train först validation sen) 
	loss = 0,01648 & 0,07377 (train först validation sen)
	moved data = 19,32
	rotated data = 86,84

	At 0.2 Learning Rate, the validation and training model is much more even than at the previous 0.5 LR. The accuracy stops at around 0.985 and the loss rate stops at around 0.02.
	
	1m 49s
	
Run #5:
	Settings:
	Epochs = 50
	Learning Rate = 0.45
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (8, 8)

	accuracy = 0,9993 & 0,9869 (train först validation sen) 
	loss = 3,9969 * 10^-3 & 0,05882 (train först validation sen)
	moved data = 21,2
	rotated data = 91,1

	At 0.11 LR, the training accuracy is even and stops at around 0.9946 and it's loss value at 0.02. The validation model has 		more uneven values in both accuracy and loss. It stops at around 0.985 accuracy and 0.055 loss.
	
	1m 50s










BATCH SIZE


Run #6:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 128
	Kernel Size = (8, 8)


	accuracy = 0,9974 & 0,9852 (train först validation sen) 
	loss = 0,01113 & 0,05159 (train först validation sen)
	moved data = 22,04
	rotated data = 90,16
	
	cut the step speed in half but did not change the total time, more steps!

	1m 58s

Run #7:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 64
	Kernel Size = (8, 8)

	accuracy = 0,9993 & 0,9862 (train först validation sen) 
	loss = 4,2165 *10^-3 & 0,05742 (train först validation sen)
	moved data = 22,01
	rotated data = 89,24
	
	cuts the step speed down to 4ms/step
	
	2m 24s


	accuracy går upp och loss ned men på förlust av både moved data och rotated data ifall vi går ner mera

			NEURONER

Run #8:
	Settings:
	Epochs = 50
	Learning Rate = 0.01
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (8, 8)
	Neuroner =  64

	accuracy = 0,9952 & 0,9868 (train först validation sen) 
	loss = 0,0177 & 0,04404 (train först validation sen)
	moved data = 22,11
	rotated data = 89,21

	With four times more neurons (64) than before the model achieved 0.9911/0.9854 (train/valid) accuracy and 0.03172/0.04813 		loss. It took way longer to run through all the epochs. 
	
	step speed 27m/s	

	4m 13s
	
Run #9:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (8, 8)
	Neuroner = 128

	accuracy = 0,9958 & 0,9877 (train först validation sen) 
	loss = 0,01724 & 0,04193 (train först validation sen)
	moved data = 22,21
	rotated data = 89,22

	With 128 neurons the model achieved 0.09916/0.9857 (train/valid) accuracy and 0.03089/0.04789 loss. It took almost 8 minutes 
	
	step speed 52 m/s

	8m 4s

			KERNEL SIZE OCH STRIDE

Run #10:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (10, 10)
	Strides = (2, 2)

	accuracy = 0,9904 & 0,983 (train först validation sen) 
	loss = 0,03371 & 0,0539 (train först validation sen)
	moved data = 22,17
	rotated data = 90,51
	
	41s	
Run #11:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (10, 10)
	Strides = (1, 1)

	accuracy = 0,9938 & 0,9853 (train först validation sen) 
	loss = 0,02231 & 0,04759 (train först validation sen)
	moved data = 21,07
	rotated data = 90,85
	
	1m 58s
Run #12:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (8, 8)
	Strides = (2, 2)

	accuracy = 0,9892 & 0,9827 (train först validation sen) 
	loss = 0,03571 & 0,0574 (train först validation sen)
	moved data = 23,3
	rotated data = 87,76
	
	37s	
	
			LAYERS
Run #12:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 256
	layers = 2

	accuracy = 0,9989 & 0,9872 (train först validation sen) 
	loss = 5,7956*10^-3 & 0,05679 (train först validation sen)
	moved data = 22,64
	rotated data = 91,66
	
	8min 43s

 
Non-Convolutional Model:

Run #1:
	Settings:
	Epochs = 50
	Learning Rate = 0.01
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (8, 8)

	accuracy = 0,9301 & 0,9309 (train först validation sen) 
	loss = 0,2475 & 0,2423 (train först validation sen)
	moved data = 11,98
	rotated data = 75,77
	
	7s
	
Run #2:
	Settings:
	Epochs = 50
	Learning Rate = 1
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (8, 8)

	accuracy = 0,9773 & 0,9478 (train först validation sen) 
	loss = 0,07375 & 0,2152 (train först validation sen)
	moved data = 15,66
	rotated data = 75,02

	försökte hitta gränsen där det  blir sämre.

	7s

Run #3:
	Settings:
	Epochs = 50
	Learning Rate = 0.5
	Validation Split = 0.5
	Batch Size = 256
	Kernel Size = (8, 8)
	
	accuracy = 0,996 & 0,9662 (train först validation sen) 
	loss = 0,01788 & 0,1424 (train först validation sen)
	moved data = 16,22
	rotated data = 81,52
	
	At 0.5 Learning Rate, the validation model is very uneven and differs in accuracy & loss value a lot. The training model is more stable but still worse than 0.01 LR.
	försökte hitta en gräns emellan 0.01 och 1 då 1 var för stort

	7s

Run #4:
	Settings:
	Epochs = 50
	Learning Rate = 0.4
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (8, 8)

	accuracy = 0,9937 & 0,966 (train först validation sen) 
	loss = 0,02512 & 0,1394 (train först validation sen)
	moved data = 15,8
	rotated data = 81,69

	At 0.2 Learning Rate, the validation and training model is much more even than at the previous 0.5 LR. The accuracy stops at around 0.985 and the loss rate stops at around 0.02.
	
	7s
	
Run #5:
	Settings:
	Epochs = 50
	Learning Rate = 0.45
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (8, 8)

	accuracy = 0,9955 & 0,9647 (train först validation sen) 
	loss = 0,02002 & 0,1433 (train först validation sen)
	moved data = 16,3
	rotated data = 81,71

	At 0.11 LR, the training accuracy is even and stops at around 0.9946 and it's loss value at 0.02. The validation model has 		more uneven values in both accuracy and loss. It stops at around 0.985 accuracy and 0.055 loss.
	
	7s




				BATCH SIZE


Run #6:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 128
	Kernel Size = (8, 8)


	accuracy = 0,9866 & 0,9681 (train först validation sen) 
	loss = 0,04838 & 0,116 (train först validation sen)
	moved data = 15,36
	rotated data = 82,68
	
	cut the step speed in half but did not change the total time, more steps!

	12s

Run #7:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 64
	Kernel Size = (8, 8)

	accuracy = 0,9935 & 0,9633 (train först validation sen) 
	loss = 0,02563 & 0,1467 (train först validation sen)
	moved data = 16,79
	rotated data = 81,38
	
	cuts the step speed down to 4ms/step
	
	23s


	accuracy går upp och loss ned men på förlust av både moved data och rotated data ifall vi går ner mera

				NEURONER

Run #8:
	Settings:
	Epochs = 50
	Learning Rate = 0.01
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (8, 8)
	Neuroner =  64

	accuracy = 0,9855 & 0,9724 (train först validation sen) 
	loss = 0,05508 & 0,1008 (train först validation sen)
	moved data = 16,18
	rotated data = 83,17

	With four times more neurons (64) than before the model achieved 0.9911/0.9854 (train/valid) accuracy and 0.03172/0.04813 		loss. It took way longer to run through all the epochs. 
	
	step speed 800u/s	

	8s
	
Run #9:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (8, 8)
	Neuroner = 128

	accuracy = 0,9903 & 0,9732 (train först validation sen) 
	loss = 0,0412 & 0,08945 (train först validation sen)
	moved data = 15,62
	rotated data = 85,43

	With 128 neurons the model achieved 0.09916/0.9857 (train/valid) accuracy and 0.03089/0.04789 loss. It took almost 8 minutes 
	
	step speed 1 m/s

	9s


















































Run #10:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (16, 16)
	Strides = (2, 2)

	Doubling the Kernel Size and Strides the model achieved 0.9815/0.9765 accuracy in training and validation
	and 0.06418/0.08072 loss. The average accuracy is worse with these values.

Run #11:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (12, 12)
	Strides = (2, 2)

	Lowering the Kernel Size a tiny bit the model reached a little better accuracy and loss 
	at around 0.9845/0.9793 & 0.05364/0.0684. The moved data average accuracy was at 20.88, a little better than the previous 		model.

Run #12:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (12, 12)
	Strides = (1, 1)

	This model reached 0.9898/0.9857 accuracy & 0.03578/0.05074 loss. Moved data: 21.24 avg accuracy. Rotated data: 89.03 avg.

Run #13:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (20, 20)
	Strides = (1, 1)

	0.9836/0.9778 accuracy & 0.0577/0.07254 loss. Moved data avg accuracy: 18.58. Rotated: 85.85 avg.

Run #14:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (15, 15)
	Strides = (1, 1)

	0.9896/0.9835 accuracy & 0.03717/0.05467 loss. Moved data avg accuracy: 20.12. Rotated: 89.55 avg.

Run #15:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (14, 14)
	Strides = (1, 1)

	Exactly the same as the previous one.

Run #16:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (10, 10)
	Strides = (1, 1)

	Almost identical to Run #12.

Run #17:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (10, 10)
	Strides = (2, 2)

	0.9861/0.9815 accuracy. 0.0472/0.06246 loss. Moved data: 21.48 avg. Rotated: 88.2 avg.

Run #18:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (20, 20)
	Strides = (2, 2)

	Garbage.

Run #19:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (6, 6)
	Strides = (1, 1)

	Worse and slower.

Run #20:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (9, 9)
	Strides = (1, 1)

	0.9905/0.9847 accuracy & 0.0336/0.05163 loss. Moved data: 21.94 avg. Rotated: 89.86 avg

Run #21:
	Settings:
	Epochs = 50
	Learning Rate = 0.1
	Validation Split = 0.2
	Batch Size = 256
	Kernel Size = (9, 9)
	Strides = (1, 1)

	After adding a new layer to the model it achieved 0.9957/0.9841 accuracy and 0.01539/0.05914 loss. Moved: 21.3 avg. 
	Rotated: 91.11 avg. The model took nine minutes to train and validate. Each step took around 62ms.



c. Det vanliga neuronnätet (non-convolutional) gick igenom varje epok mycket snabbare än CNN. 
Ett Non-convolutional neural network går igenom en bild varje pixel för sig, medan ett convolutional NN går igenom en bild med större block som innehåller sub-NNs.

d. Under första körningen vinner CNN i jämförelse med ANN då efter 50 epoker hade den en bättre accuracy med mycket mindre loss. Dock tar CNN mycket längre tid att köra igenom alla 50 epoker i jämförelse med ANN.

e. Lär sig lite mer, men tar väldigt mycket mer tid. Inte värt att använda då modeller med mindre neuroner kan lära sig ungefär lika mycket på mycket kortare tid.

f. Att öka Kernel Size över (10, 10) försämrar modellen. Att öka Strides försämrar också modellen. 

g. Precisionen blir mycket bättre men detta i kostnad mot träningstid, som även ökar väldigt mycket.





8. Egna experiment:

Conv:
Test #1:
	Settings:
	Epochs = 50
	Learning Rate = 0.3
	Batch Size = 64
	Kernel Size = (8, 8)
	Strides = (1, 1)
	Layers = 2
	Neurons = 32


	1/0.9897 Accuracy (train/validation). 2.1445*10^-5/0.007792 (train/validation) Loss. Moved: 23.74 avg. Rotated: 89.92 avg.
	21 minutes 47 seconds elapsed.


Test #2:
	Settings:
	Epochs = 50
	Learning Rate = 0.35
	Batch Size = 64
	Kernel Size = (8, 8)
	Strides = (1, 1)
	Layers = 1
	Neurons = 16


	0.9963/0.9794 Accuracy (train/validation). 0.01093/0.1201 Loss (train/validation). Moved: 21.01 avg. Rotated: 86.47 avg.
	2 minutes 15 seconds elapsed.


Test #3:
	Settings:
	Epochs = 50
	Learning Rate = 0.4
	Batch Size = 64
	Kernel Size = (8, 8)
	Strides = (1, 1)
	Layers = 1
	Neurons = 32


	1/0.9875 Accuracy. 2.9956*10^-4/0.06705 Loss. Moved: 21.65 avg. Rotated: 90.17 avg.
	2 minutes 57 seconds elapsed.


Test #4:
	Settings:
	Epochs = 50
	Learning Rate = 0.4
	Batch Size = 32
	Kernel Size = (8, 8)
	Strides = (1, 1)
	Layers = 1
	Neurons = 64

	1/0.9866 Accuracy. 8.0342*10^-5/0.0895 Loss. Moved: 21.27 avg. Rotated: 89.29 avg.
	5m 22s elapsed.


Test #5:
	Settings:
	Epochs = 50
	Learning Rate = 0.35
	Batch Size = 128
	Kernel Size = (8, 8)
	Strides = (1, 1)
	Layers = 1
	Neurons = 32


	1/0.9877 Accuracy. 8.7093*10^-4/0.05637 Loss. Moved: 21.86 avg. Rotated: 89.97 avg.
	2m 59s elapsed.


Answer: Test #3 was the best!! around!!! nothing's gonna ever keep me down!!!



non-conv:
Test #1:
	Settings:
	Epochs = 50
	Learning Rate = 0.3
	Batch Size = 64´
	Neurons = 32


	0.994/0.9651 Accuracy. 0.01946/0.2458 Loss. Moved: 15.54 avg. Rotated: 82.28 avg.
	23s elapsed.


Test #2:
	Settings:
	Epochs = 50
	Learning Rate = 0.4
	Batch Size = 64
	Neurons = 64


	1/0.9769 Accuracy. 6.8722*10^-4/0.1196 Loss. Moved: 16.73 avg. Rotated: 85.98 avg.
	24s elapsed.


Test #3:
	Settings:
	Epochs = 50
	Learning Rate = 0.4
	Batch Size = 64
	Neurons = 128


	1/0.9789 Accuracy. 5.4733*10^-4/0.09306 Loss. Moved: 17.39 avg. Rotated: 87.68 avg.
	25s elapsed.


Test #4:
	Settings:
	Epochs = 50
	Learning Rate = 0.4
	Batch Size = 64
	Neurons = 1024


	1/0.9827 Accuracy. 4.2237*10^-4/0.07589 Loss. Moved: 17.51 avg. Rotated: 88.36 avg.
	1m 19s elapsed.

Test #5:
	Settings:
	Epochs = 50
	Learning Rate = 0.4
	Batch Size = 64
	Neurons = 16384


	1/0.9842 Accuracy. 4.05*10^-4/0.07187 Loss. Moved: 17.39 avg. Rotated: 88.42 avg.
	13m 47s elapsed.


Test #6:
	Settings:
	Epochs = 50
	Learning Rate = 0.4
	Batch Size = 32
	Neurons = 1024


	1/0.9836 Accuracy. 1.5577*10^-4/0.08045 Loss. Moved: 17.69 avg. Rotated: 89.04 avg.
	2m 36s elapsed.


Answer: Test #6 was best!! around!!! nothing's gonna ever keep me down!!

